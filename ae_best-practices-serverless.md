---

copyright:
  years: 2017, 2024
lastupdated: "2024-05-31"

subcollection: watsonxdata

---


{:new_window: target="_blank"}
{:shortdesc: .shortdesc}
{:codeblock: .codeblock}
{:screen: .screen}
{:note: .note}
{:pre: .pre}


# Best practices
{: #best-practices-serverless}

Use the following set of recommended guidelines when provisioning and managing your serverless instances and when running Spark applications.


| Best Practice  | Description | Reference Link |
|----------------|-------------|----------------|
| Upgrade to the latest Spark version | As open source Spark versions are released, they are made available in {{site.data.keyword.lakehouse_short}} Spark instance for use. Watch out for the announcement of a new Spark versions in the Release Notes section and upgrade the runtime of your instance to move your applications to latest Spark runtime. Older runtimes are be deprecated and eventually removed as newer versions are released. Make sure you test your applications on the new runtime before making changes on the production instances. For more information, see [View and edit Native Spark engine detail](watsonxdata?topic=watsonxdata-view_edit). | - [Release notes](watsonxdata?topic=watsonxdata-release) |
| Grant role-based access | You should grant role-based access to all users on the {{site.data.keyword.lakehouse_short}} instances based on their requirements. | - [Managing roles and privileges](watsonxdata?topic=watsonxdata-role_priv) |
| Choose the right {{site.data.keyword.cos_full_notm}} configuration | - **Disaster Recovery (DR) Resiliency**: You should use the {{site.data.keyword.cos_full_notm}} Cross Regional resiliency option that backs up your data across several different cities in a region. In contrast, the Regional resiliency option back ups data in a single data center.  \n- **Encryption**: {{site.data.keyword.cos_full_notm}} comes with default built-in encryption. You can also configure {{site.data.keyword.cos_short}} to work with the BYOK Key Protect service.  \n- **Service credentials**: By default, {{site.data.keyword.cos_full_notm}} uses IAM-style credentials. If you want to work with AWS-style credentials, you need to use the "Include HMAC Credential" option as described in **Service credentials**.  \n- **Direct endpoints for {{site.data.keyword.cos_full_notm}}**: Always use direct endpoints for connectivity to the {{site.data.keyword.cos_full_notm}} instance. This applies to the {{site.data.keyword.cos_full_notm}} home instance as well as endpoints used from your applications (either your code or what you pass as parameters in the configurations at instance level or application level). Direct endpoints provide better performance than public endpoints and do not incur charges for any outgoing or incoming bandwidth. | - **Disaster Recovery (DR) Resiliency**: [{{site.data.keyword.cos_full_notm}} documentation.](/docs/cloud-object-storage/info?topic=cloud-object-storage-endpoints#endpoints)  \n- **Encryption**: [Getting started with encryption keys](/docs/key-protect?topic=key-protect-getting-started-tutorial#getting-started-tutorial) and [{{site.data.keyword.cos_short}} manage encryption](/docs/cloud-object-storage/basics?topic=cloud-object-storage-encryption#encryption)  \n- **Service credentials**: [Service credentials](/docs/cloud-object-storage/iam?topic=cloud-object-storage-service-credentials#service-credentials)  \n- **Direct endpoints for {{site.data.keyword.cos_full_notm}}**: [Endpoints and storage locations](/docs/cloud-object-storage?topic=cloud-object-storage-endpoints) |
| Running applications with resource overcommitment | There is a quota associated with each Spark engine. When applications are submitted on an instance, they are allocated resources from the instance quota. If an application requests resources beyond the available quota, the application will either not start or will run with less than the requested resources, which might result in the application running slower than expected or, in some cases, in the application failing. You should always monitor the current resource consumption on an instance to ensure that your applications are running comfortably within the given limits. You can adjust the limits through a support ticket if required. | NA |
| Customize your service instance | - You might need to customize your service instance to bring in Python or conda packages that are not preinstalled, or bring in some files(certificates or config files) that are to be made available to Spark applications. Based on your needs, customize your instance using library sets and use these library sets when submitting applications.  \n - The size of your library set has a bearing on the application startup time and the executor startup time (when you auto-scale applications). Also note there is an upper limit for the size of a library set, namely 2 GB. So if different applications need different library sets, it is better for you to use separate library sets, so that they can be specified individually at the time the application is submitted.  \n - Use customization only to bring in files that cannot be brought in by the application details parameters. See [Parameters for submitting Spark applications](/docs/AnalyticsEngine?topic=AnalyticsEngine-spark-app-rest-api#spark-submit-parms). You must use the standard spark-submit equivalent parameter options such as the `files`, `jars`, `packages` and `pyFiles` options if that fits your use case. Only if you need files that don't fit into any of these categories, for example a self signed certificate, a JAAS configuration file, or a `.so` file, you should use the "customization for file download" option.  | - [Customization options](watsonxdata?topic=watsonxdata-cust-instance#cust-options) |
| Apply filters when retrieving list of applications | When you need to retrieve list of applications either in UI or using the API or CLI, it is better to apply the appropriate filters and retrieve the set that you need. |
| Use other services or tools for supporting functions | Apart from using an {{site.data.keyword.la_full_notm}} and {{site.data.keyword.cos_full_notm}} instance and depending on your use case, you might want to use other supporting tools and services. For instance, you can use Apache Airflow (managed by you) for orchestrating, scheduling and automating your applications. You can also make use of IBM Secrets Manager to store the secrets required for your applications and use your automation scripts to read the secrets from the Secrets Manager before submitting your applications. You can also get creative with your application arguments, passing a token required to read the required secrets from the Secrets Manager directly from within your application. | - [Configuring Secrets Manager](/docs/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager) |
| Use instances in alternate regions for backup and disaster recovery | Currently, {{site.data.keyword.iae_full_notm}} Serverless instances can be created in two regions, namely Dallas(`us-south`) and Frankfurt(`eu-de`). Although it is advisable to create your instances in the same region where your data is located, it is always useful to create a backup instance in an alternate region with the same set of configurations as your primary instance, in case the primary instance becomes unavailable or unusable. Your automations should enable switching application submissions between the two regions if required.| NA |
| Use separate buckets and service credentials for application files, data files, and home instance | Use the "separation of concerns" principle to distinguish the access between different resources.  \n - Do not store data or application files in the home instance bucket.  \n - Use separate buckets for data and application files.  \n - Use separate access credentials (IAM Key based) with restricted access to the bucket for application files and the bucket that contains your data. | - [Assigning access to an individual bucket](/docs/cloud-object-storage?topic=cloud-object-storage-iam-bucket-permissions&interface=ui) |
{: caption="Table 1. Best practices when using serverless instances including detailed descriptions and reference links" caption-side="top"}
{: #table-1}
{: row-headers}
